

# ğŸš€ Video-to-Text Sistemi â€” ModÃ¼ler & GeliÅŸtirici OdaklÄ± Rehber (PaddleOCR v5)

### ğŸ¯ Hedef:

Videolardaki metinleri zaman bilgisi ve konum ile birlikte Ã§Ä±karÄ±p JSON formatÄ±nda kaydeden, modÃ¼ler ve geniÅŸletilebilir bir OCR sistemi kurmak.

modelleri manuel indirdim o yÃ¼zden bu yollarÄ± kullan yoksa v3 Ã¼ kullanÄ±yor sistem. 

MODELS_DIR = r"C:\Users\ASUS\Desktop\videotext\models\ppocrv5"
DET_DIR    = os.path.join(MODELS_DIR, "PP-OCRv5_server_det")
REC_DIR    = os.path.join(MODELS_DIR, "PP-OCRv5_server_rec")


---

## ğŸ“¦ Proje YapÄ±sÄ± ve Kurulum

**1. Yeni klasÃ¶r oluÅŸtur ve sanal ortam kur:**

```bash
mkdir video_processor && cd video_processor
python -m venv .venv
.venv\Scripts\activate  # (Linux/macOS: source .venv/bin/activate)
```

**2. `pyproject.toml` ile baÄŸÄ±mlÄ±lÄ±klarÄ± tanÄ±mla:**

```toml
[project]
name = "video_processor"
version = "0.1.0"
requires-python = ">=3.10"

[project.dependencies]
paddleocr         = ">=3.1.0"
paddlepaddle-gpu  = ">=2.6"
opencv-python     = "*"
pydantic          = "^2"
pyyaml            = "*"
rapidfuzz         = "*"
symspellpy        = "*"
scikit-learn      = "*"
spacy             = "*"
```

Kur:

```bash
pip install -e .
```

**3. KlasÃ¶r yapÄ±sÄ±:**

```
video_processor/
â”œâ”€â”€ video_processor/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ engine.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ io/
â”‚   â”‚   â”œâ”€â”€ extractor.py
â”‚   â”‚   â””â”€â”€ writer.py
â”‚   â”œâ”€â”€ ocr/
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â””â”€â”€ paddle.py
â”œâ”€â”€ models/
â”œâ”€â”€ video/
â”œâ”€â”€ tests/
```

---

## ğŸ§  1. `engine.py` â€” Ana Motor (Pipeline)

### ğŸ¯ AmaÃ§:

TÃ¼m sistemi uÃ§tan uca zincirlemek: video karelerini oku â†’ OCR â†’ Ã§Ä±ktÄ±yÄ± yaz.

### ğŸ” Detay:

```python
from .io.extractor import FrameExtractor
from .ocr.paddle import PaddleOCRWrapper
from .io.writer import JsonWriter

def run_pipeline(video_path, out_path, *, step=15, gpu=True):
    extractor = FrameExtractor(video_path, step)
    ocr       = PaddleOCRWrapper(gpu)
    writer    = JsonWriter(out_path)

    for idx, frame, ts in extractor:
        for bbox, txt, conf in ocr.recognize(frame):
            writer.add(ts, bbox, txt, conf)

    writer.finalize()
```

### ğŸ“Œ Kritik Noktalar:

* `run_pipeline` iÅŸin kalbidir.
* Sonradan kolayca `text_filter`, `entity_extractor`, `super_resolution` gibi modÃ¼ller eklenebilir.
* `step` deÄŸeri performans ve doÄŸruluk arasÄ±nda denge saÄŸlar.

---

## ğŸ“½ 2. `io/extractor.py` â€” Video Frame AyÄ±klayÄ±cÄ±

### ğŸ¯ AmaÃ§:

OpenCV ile videoyu kare kare Ã§Ã¶zÃ¼mlemek ve her karenin zaman bilgisini almak.

### ğŸ” Detay:

```python
import cv2
class FrameExtractor:
    def __init__(self, path, step=15):
        self.cap  = cv2.VideoCapture(path)
        self.step = step
    def __iter__(self):
        idx = 0
        while self.cap.isOpened():
            ok, frame = self.cap.read()
            if not ok: break
            if idx % self.step == 0:
                ts = self.cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0
                yield idx, frame, ts
            idx += 1
        self.cap.release()
```

### ğŸ’¡ Notlar:

* `step=15` â†’ 1 saniyede 30 kare varsa, her 0.5 saniyede 1 kare alÄ±r.
* `ts` (timestamp) OCR sonucuna zaman bilgisi ekler, bu sayede altyazÄ±/sahne zamanlamasÄ± yapÄ±labilir.

---

## ğŸ”¤ 3. `ocr/base.py` â€” OCR ArayÃ¼zÃ¼ (Soyut SÄ±nÄ±f)

### ğŸ¯ AmaÃ§:

OCR motorlarÄ± (PaddleOCR, Tesseract, Donut...) iÃ§in ortak arayÃ¼z belirlemek.

```python
from abc import ABC, abstractmethod
class BaseOCR(ABC):
    @abstractmethod
    def recognize(self, frame): ...
```

### ğŸ“Œ Neden Gerekli?

* PaddleOCR yerine Donut, EasyOCR, CRNN gibi modelleri entegre etmek istediÄŸinde sadece `.paddle.py` deÄŸil, `.donut.py` gibi yeni bir dosya eklemen yeterli olur.

---

## ğŸ¤– 4. `ocr/paddle.py` â€” PaddleOCR Entegrasyonu

### ğŸ¯ AmaÃ§:

PaddleOCRâ€™Ä± wrapper sÄ±nÄ±fÄ±na sararak daha basit ve modÃ¼ler kullanÄ±m saÄŸlamak.

```python
from paddleocr import PaddleOCR
from .base import BaseOCR

class PaddleOCRWrapper(BaseOCR):
    def __init__(self, gpu=True):
        self.ocr = PaddleOCR(
            det_model_dir="models/ppocrv5/PP-OCRv5_server_det",
            rec_model_dir="models/ppocrv5/PP-OCRv5_server_rec",
            lang="tr", use_gpu=gpu
        )

    def recognize(self, frame):
        for det in self.ocr.ocr(frame, cls=True):
            txt, conf = det[1][0]
            (x1, y1), (x2, y2) = det[0][0], det[0][2]
            yield (x1, y1, x2, y2), txt, conf
```

### ğŸ§ª GÃ¼Ã§lÃ¼ Noktalar:

* `cls=True` â†’ AÃ§Ä±lÄ± metinleri de doÄŸru okumaya Ã§alÄ±ÅŸÄ±r.
* TÃ¼rkÃ§e iÃ§in `lang="tr"` zorunlu.
* `yield` ile Ã§ok bÃ¼yÃ¼k videolarda belleÄŸe yÃ¼klenmeden iÅŸlem yapÄ±labilir.

---

## ğŸ’¾ 5. `io/writer.py` â€” JSON Kaydedici

### ğŸ¯ AmaÃ§:

OCR sonuÃ§larÄ±nÄ± zaman ve konum bilgileriyle birlikte JSON olarak saklamak.

```python
import json
class JsonWriter:
    def __init__(self, path):
        self.path = path
        self.data = []
    def add(self, t, bbox, text, conf):
        self.data.append({"t": t, "bbox": bbox,
                          "text": text, "conf": conf})
    def finalize(self):
        with open(self.path, "w", encoding="utf-8") as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)
```

### ğŸ” Format Ã–rneÄŸi:

```json
{
  "t": 3.5,
  "bbox": [102, 240, 420, 300],
  "text": "Kredi notu sorgulama",
  "conf": 0.92
}
```

---

## ğŸ–¥ 6. `cli.py` â€” Komut SatÄ±rÄ± ArayÃ¼zÃ¼

### ğŸ¯ AmaÃ§:

KullanÄ±cÄ±dan video, Ã§Ä±ktÄ± dosyasÄ±, iÅŸlem adÄ±mÄ± ve GPU/CPU seÃ§imi almak.

```python
import argparse
from .engine import run_pipeline

def build_parser():
    p = argparse.ArgumentParser("Video âœ Metin")
    p.add_argument("-v", "--video", default="video/sample.mp4")
    p.add_argument("-o", "--out",   default="report.json")
    p.add_argument("--step", type=int, default=15)
    p.add_argument("--cpu", action="store_true")
    return p

def main():
    args = build_parser().parse_args()
    run_pipeline(args.video, args.out, step=args.step, gpu=not args.cpu)

if __name__ == "__main__":
    main()
```

### âœ… KullanÄ±m:

```bash
python -m video_processor.cli -v video/Ã¶rnek.mp4 -o rapor.json --step 10
```

---

## âœ… Sistem ArtÄ±k HazÄ±r!

Projeyi Ã§alÄ±ÅŸtÄ±r:

```bash
python -m video_processor.cli
```

Ve `report.json` dosyasÄ± aÅŸaÄŸÄ±daki gibi oluÅŸur:

```json
[
  {
    "t": 1.5,
    "bbox": [120, 200, 460, 250],
    "text": "Enflasyon raporu aÃ§Ä±klandÄ±",
    "conf": 0.94
  }
]
```

---

## ğŸ“ˆ Sonraki GeliÅŸtirme AÅŸamalarÄ±

| AdÄ±m | Eklenecek ModÃ¼l | AÃ§Ä±klama                                                |
| ---- | --------------- | ------------------------------------------------------- |
| 2    | `preprocess/`   | CLAHE + Deskew ile gÃ¶rÃ¼ntÃ¼ kalitesi artÄ±rÄ±lÄ±r           |
| 3    | `track/`        | Optical flow + IoU ile aynÄ± metin gruplarÄ± takip edilir |
| 4    | `post/`         | RapidFuzz ile tekrar eden yazÄ±lar filtrelenir           |
| 5    | `nlp/`          | spaCy / Stanza ile kiÅŸi, marka, yer isimleri Ã§Ä±karÄ±lÄ±r  |
| 6    | `report/`       | Ã–zet Ã§Ä±karÄ±mÄ± veya Ã¶zel rapor Ã¼retimi                   |

---



Args:
            input (Union[str, list[str], np.ndarray, list[np.ndarray]]): Input image of pdf path(s) or numpy array(s).
            use_doc_orientation_classify (Optional[bool]): Whether to use document orientation classification.
            use_doc_unwarping (Optional[bool]): Whether to use document unwarping.
            use_textline_orientation (Optional[bool]): Whether to use textline orientation prediction.
            text_det_limit_side_len (Optional[int]): Maximum side length for text detection.
            text_det_limit_type (Optional[str]): Type of limit to apply for text detection.
            text_det_max_side_limit (Optional[int]): Maximum side length for text detection.
            text_det_thresh (Optional[float]): Threshold for text detection.
            text_det_box_thresh (Optional[float]): Threshold for text detection boxes.
            text_det_unclip_ratio (Optional[float]): Ratio for unclipping text detection boxes.
            text_rec_score_thresh (Optional[float]): Score threshold for text recognition.
        Returns:
            OCRResult: Generator yielding OCR results for each input image.
        """