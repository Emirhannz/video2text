

# 🚀 Video-to-Text Sistemi — Modüler & Geliştirici Odaklı Rehber (PaddleOCR v5)

### 🎯 Hedef:

Videolardaki metinleri zaman bilgisi ve konum ile birlikte çıkarıp JSON formatında kaydeden, modüler ve genişletilebilir bir OCR sistemi kurmak.

modelleri manuel indirdim o yüzden bu yolları kullan yoksa v3 ü kullanıyor sistem. 

MODELS_DIR = r"C:\Users\ASUS\Desktop\videotext\models\ppocrv5"
DET_DIR    = os.path.join(MODELS_DIR, "PP-OCRv5_server_det")
REC_DIR    = os.path.join(MODELS_DIR, "PP-OCRv5_server_rec")


---

## 📦 Proje Yapısı ve Kurulum

**1. Yeni klasör oluştur ve sanal ortam kur:**

```bash
mkdir video_processor && cd video_processor
python -m venv .venv
.venv\Scripts\activate  # (Linux/macOS: source .venv/bin/activate)
```

**2. `pyproject.toml` ile bağımlılıkları tanımla:**

```toml
[project]
name = "video_processor"
version = "0.1.0"
requires-python = ">=3.10"

[project.dependencies]
paddleocr         = ">=3.1.0"
paddlepaddle-gpu  = ">=2.6"
opencv-python     = "*"
pydantic          = "^2"
pyyaml            = "*"
rapidfuzz         = "*"
symspellpy        = "*"
scikit-learn      = "*"
spacy             = "*"
```

Kur:

```bash
pip install -e .
```

**3. Klasör yapısı:**

```
video_processor/
├── video_processor/
│   ├── __init__.py
│   ├── engine.py
│   ├── cli.py
│   ├── io/
│   │   ├── extractor.py
│   │   └── writer.py
│   ├── ocr/
│   │   ├── base.py
│   │   └── paddle.py
├── models/
├── video/
├── tests/
```

---

## 🧠 1. `engine.py` — Ana Motor (Pipeline)

### 🎯 Amaç:

Tüm sistemi uçtan uca zincirlemek: video karelerini oku → OCR → çıktıyı yaz.

### 🔍 Detay:

```python
from .io.extractor import FrameExtractor
from .ocr.paddle import PaddleOCRWrapper
from .io.writer import JsonWriter

def run_pipeline(video_path, out_path, *, step=15, gpu=True):
    extractor = FrameExtractor(video_path, step)
    ocr       = PaddleOCRWrapper(gpu)
    writer    = JsonWriter(out_path)

    for idx, frame, ts in extractor:
        for bbox, txt, conf in ocr.recognize(frame):
            writer.add(ts, bbox, txt, conf)

    writer.finalize()
```

### 📌 Kritik Noktalar:

* `run_pipeline` işin kalbidir.
* Sonradan kolayca `text_filter`, `entity_extractor`, `super_resolution` gibi modüller eklenebilir.
* `step` değeri performans ve doğruluk arasında denge sağlar.

---

## 📽 2. `io/extractor.py` — Video Frame Ayıklayıcı

### 🎯 Amaç:

OpenCV ile videoyu kare kare çözümlemek ve her karenin zaman bilgisini almak.

### 🔍 Detay:

```python
import cv2
class FrameExtractor:
    def __init__(self, path, step=15):
        self.cap  = cv2.VideoCapture(path)
        self.step = step
    def __iter__(self):
        idx = 0
        while self.cap.isOpened():
            ok, frame = self.cap.read()
            if not ok: break
            if idx % self.step == 0:
                ts = self.cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0
                yield idx, frame, ts
            idx += 1
        self.cap.release()
```

### 💡 Notlar:

* `step=15` → 1 saniyede 30 kare varsa, her 0.5 saniyede 1 kare alır.
* `ts` (timestamp) OCR sonucuna zaman bilgisi ekler, bu sayede altyazı/sahne zamanlaması yapılabilir.

---

## 🔤 3. `ocr/base.py` — OCR Arayüzü (Soyut Sınıf)

### 🎯 Amaç:

OCR motorları (PaddleOCR, Tesseract, Donut...) için ortak arayüz belirlemek.

```python
from abc import ABC, abstractmethod
class BaseOCR(ABC):
    @abstractmethod
    def recognize(self, frame): ...
```

### 📌 Neden Gerekli?

* PaddleOCR yerine Donut, EasyOCR, CRNN gibi modelleri entegre etmek istediğinde sadece `.paddle.py` değil, `.donut.py` gibi yeni bir dosya eklemen yeterli olur.

---

## 🤖 4. `ocr/paddle.py` — PaddleOCR Entegrasyonu

### 🎯 Amaç:

PaddleOCR’ı wrapper sınıfına sararak daha basit ve modüler kullanım sağlamak.

```python
from paddleocr import PaddleOCR
from .base import BaseOCR

class PaddleOCRWrapper(BaseOCR):
    def __init__(self, gpu=True):
        self.ocr = PaddleOCR(
            det_model_dir="models/ppocrv5/PP-OCRv5_server_det",
            rec_model_dir="models/ppocrv5/PP-OCRv5_server_rec",
            lang="tr", use_gpu=gpu
        )

    def recognize(self, frame):
        for det in self.ocr.ocr(frame, cls=True):
            txt, conf = det[1][0]
            (x1, y1), (x2, y2) = det[0][0], det[0][2]
            yield (x1, y1, x2, y2), txt, conf
```

### 🧪 Güçlü Noktalar:

* `cls=True` → Açılı metinleri de doğru okumaya çalışır.
* Türkçe için `lang="tr"` zorunlu.
* `yield` ile çok büyük videolarda belleğe yüklenmeden işlem yapılabilir.

---

## 💾 5. `io/writer.py` — JSON Kaydedici

### 🎯 Amaç:

OCR sonuçlarını zaman ve konum bilgileriyle birlikte JSON olarak saklamak.

```python
import json
class JsonWriter:
    def __init__(self, path):
        self.path = path
        self.data = []
    def add(self, t, bbox, text, conf):
        self.data.append({"t": t, "bbox": bbox,
                          "text": text, "conf": conf})
    def finalize(self):
        with open(self.path, "w", encoding="utf-8") as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)
```

### 🔍 Format Örneği:

```json
{
  "t": 3.5,
  "bbox": [102, 240, 420, 300],
  "text": "Kredi notu sorgulama",
  "conf": 0.92
}
```

---

## 🖥 6. `cli.py` — Komut Satırı Arayüzü

### 🎯 Amaç:

Kullanıcıdan video, çıktı dosyası, işlem adımı ve GPU/CPU seçimi almak.

```python
import argparse
from .engine import run_pipeline

def build_parser():
    p = argparse.ArgumentParser("Video ➜ Metin")
    p.add_argument("-v", "--video", default="video/sample.mp4")
    p.add_argument("-o", "--out",   default="report.json")
    p.add_argument("--step", type=int, default=15)
    p.add_argument("--cpu", action="store_true")
    return p

def main():
    args = build_parser().parse_args()
    run_pipeline(args.video, args.out, step=args.step, gpu=not args.cpu)

if __name__ == "__main__":
    main()
```

### ✅ Kullanım:

```bash
python -m video_processor.cli -v video/örnek.mp4 -o rapor.json --step 10
```

---

## ✅ Sistem Artık Hazır!

Projeyi çalıştır:

```bash
python -m video_processor.cli
```

Ve `report.json` dosyası aşağıdaki gibi oluşur:

```json
[
  {
    "t": 1.5,
    "bbox": [120, 200, 460, 250],
    "text": "Enflasyon raporu açıklandı",
    "conf": 0.94
  }
]
```

---

## 📈 Sonraki Geliştirme Aşamaları

| Adım | Eklenecek Modül | Açıklama                                                |
| ---- | --------------- | ------------------------------------------------------- |
| 2    | `preprocess/`   | CLAHE + Deskew ile görüntü kalitesi artırılır           |
| 3    | `track/`        | Optical flow + IoU ile aynı metin grupları takip edilir |
| 4    | `post/`         | RapidFuzz ile tekrar eden yazılar filtrelenir           |
| 5    | `nlp/`          | spaCy / Stanza ile kişi, marka, yer isimleri çıkarılır  |
| 6    | `report/`       | Özet çıkarımı veya özel rapor üretimi                   |

---



Args:
            input (Union[str, list[str], np.ndarray, list[np.ndarray]]): Input image of pdf path(s) or numpy array(s).
            use_doc_orientation_classify (Optional[bool]): Whether to use document orientation classification.
            use_doc_unwarping (Optional[bool]): Whether to use document unwarping.
            use_textline_orientation (Optional[bool]): Whether to use textline orientation prediction.
            text_det_limit_side_len (Optional[int]): Maximum side length for text detection.
            text_det_limit_type (Optional[str]): Type of limit to apply for text detection.
            text_det_max_side_limit (Optional[int]): Maximum side length for text detection.
            text_det_thresh (Optional[float]): Threshold for text detection.
            text_det_box_thresh (Optional[float]): Threshold for text detection boxes.
            text_det_unclip_ratio (Optional[float]): Ratio for unclipping text detection boxes.
            text_rec_score_thresh (Optional[float]): Score threshold for text recognition.
        Returns:
            OCRResult: Generator yielding OCR results for each input image.
        """